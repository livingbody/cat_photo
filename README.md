# ä¸€ã€ åŸºäºOxford-IIIT Petæ•°æ®é›†å®ç°PaddleHubçŒ«å’ªä¸€é”®æŠ å›¾

AiStudioåœ°å€ï¼š[https://aistudio.baidu.com/aistudio/projectdetail/2557831?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/2557831?contributionType=1)

githubåœ°å€ï¼š[https://github.com/livingbody/cat_photo](https://github.com/livingbody/cat_photo)


paddlehubåœ°å€ï¼š[catseg_mobile](catseg_mobile)

## 1.ä¸»è¦å·¥ä½œ
* ä»Oxford-IIIT Petå® ç‰©æ•°æ®é›†æå–catæ®é›†
* é‡æ–°åˆ¶ä½œlabelï¼ŒèƒŒæ™¯è®¾ç½®ä¸º0ï¼Œå›¾åƒè®¾ç½®ä¸º1
* æœ€ç»ˆiter 2100æ—¶ï¼Œ mIoU =0.7874ï¼Œä»æœ‰ä¸Šå‡ç©ºé—´ï¼Œåªæ˜¯è€—æ—¶è¾ƒé•¿ï¼Œä¸å†è®­ç»ƒ
* é€šè¿‡paddlehubéƒ¨ç½²å¯¼å‡ºçš„é™æ€æ¨¡å‹

æ¨¡å‹æ–‡ä»¶è§å½“å‰ç›®å½• **model.gz** ï¼Œ paddlehubéƒ¨ç½²è§ **catseg_mobile.zip** ã€‚

æœ€åå°±å¯ä»¥å®Œç¾æŠ å›¾äº†ï¼Œå¯ä»¥åˆ¶ä½œçŒ«çŒ«è¯ä»¶ç…§äº†ã€‚



## 2.PaddleSegç®€ä»‹
PaddleSegæ˜¯åŸºäºé£æ¡¨PaddlePaddleå¼€å‘çš„ç«¯åˆ°ç«¯å›¾åƒåˆ†å‰²å¼€å‘å¥—ä»¶ï¼Œæ¶µç›–äº†é«˜ç²¾åº¦å’Œè½»é‡çº§ç­‰ä¸åŒæ–¹å‘çš„å¤§é‡é«˜è´¨é‡åˆ†å‰²æ¨¡å‹ã€‚é€šè¿‡æ¨¡å—åŒ–çš„è®¾è®¡ï¼Œæä¾›äº†é…ç½®åŒ–é©±åŠ¨å’ŒAPIè°ƒç”¨ä¸¤ç§åº”ç”¨æ–¹å¼ï¼Œå¸®åŠ©å¼€å‘è€…æ›´ä¾¿æ·åœ°å®Œæˆä»è®­ç»ƒåˆ°éƒ¨ç½²çš„å…¨æµç¨‹å›¾åƒåˆ†å‰²åº”ç”¨ã€‚

**ç‰¹æ€§**

* é«˜ç²¾åº¦æ¨¡å‹ï¼š åŸºäºç™¾åº¦è‡ªç ”çš„åŠç›‘ç£æ ‡ç­¾çŸ¥è¯†è’¸é¦æ–¹æ¡ˆï¼ˆSSLDï¼‰è®­ç»ƒå¾—åˆ°é«˜ç²¾åº¦éª¨å¹²ç½‘ç»œï¼Œç»“åˆå‰æ²¿çš„åˆ†å‰²æŠ€æœ¯ï¼Œæä¾›äº†50+çš„é«˜è´¨é‡é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ•ˆæœä¼˜äºå…¶ä»–å¼€æºå®ç°ã€‚
* æ¨¡å—åŒ–è®¾è®¡ï¼š æ”¯æŒ15+ä¸»æµ åˆ†å‰²ç½‘ç»œ ï¼Œç»“åˆæ¨¡å—åŒ–è®¾è®¡çš„ æ•°æ®å¢å¼ºç­–ç•¥ ã€éª¨å¹²ç½‘ç»œã€æŸå¤±å‡½æ•° ç­‰ä¸åŒç»„ä»¶ï¼Œå¼€å‘è€…å¯ä»¥åŸºäºå®é™…åº”ç”¨åœºæ™¯å‡ºå‘ï¼Œç»„è£…å¤šæ ·åŒ–çš„è®­ç»ƒé…ç½®ï¼Œæ»¡è¶³ä¸åŒæ€§èƒ½å’Œç²¾åº¦çš„è¦æ±‚ã€‚
* é«˜æ€§èƒ½ï¼š æ”¯æŒå¤šè¿›ç¨‹å¼‚æ­¥I/Oã€å¤šå¡å¹¶è¡Œè®­ç»ƒã€è¯„ä¼°ç­‰åŠ é€Ÿç­–ç•¥ï¼Œç»“åˆé£æ¡¨æ ¸å¿ƒæ¡†æ¶çš„æ˜¾å­˜ä¼˜åŒ–åŠŸèƒ½ï¼Œå¯å¤§å¹…åº¦å‡å°‘åˆ†å‰²æ¨¡å‹çš„è®­ç»ƒå¼€é”€ï¼Œè®©å¼€å‘è€…æ›´ä½æˆæœ¬ã€æ›´é«˜æ•ˆåœ°å®Œæˆå›¾åƒåˆ†å‰²è®­ç»ƒã€‚


```python
! git clone https://gitee.com/paddlepaddle/PaddleSeg.git  --depth=1
```

    Cloning into 'PaddleSeg'...
    remote: Enumerating objects: 1589, done.[K
    remote: Counting objects: 100% (1589/1589), done.[K
    remote: Compressing objects: 100% (1354/1354), done.[K
    remote: Total 1589 (delta 309), reused 1117 (delta 142), pack-reused 0[K
    Receiving objects: 100% (1589/1589), 88.49 MiB | 5.57 MiB/s, done.
    Resolving deltas: 100% (309/309), done.
    Checking connectivity... done.


## 3.æ•°æ®é›†åˆ¶ä½œ

> éœ€è¦æ‰‹åŠ¨åˆ é™¤dataset/annotations/list.txtæ–‡ä»¶å¤´ï¼Œä¾¿äºpandasè¯»å–ï¼Œå¦‚éº»çƒ¦ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å·²åˆ¶ä½œå¥½çš„æ•°æ®é›†äºŒï¼Œcatæ•°æ®é›†ã€‚


```python
# è§£å‹ç¼©æ•°æ®é›†
!mkdir dataset
!tar -xvf data/data50154/images.tar.gz -C dataset/
!tar -xvf data/data50154/annotations.tar.gz -C dataset/
```


```python
# æŸ¥çœ‹listæ–‡ä»¶
!head -n 10 dataset/annotations/list.txt
```

    #Image CLASS-ID SPECIES BREED ID
    #ID: 1:37 Class ids
    #SPECIES: 1:Cat 2:Dog
    #BREED ID: 1-25:Cat 1:12:Dog
    #All images with 1st letter as captial are cat images
    #images with small first letter are dog images
    Abyssinian_100 1 1 1
    Abyssinian_101 1 1 1
    Abyssinian_102 1 1 1
    Abyssinian_103 1 1 1



```python
# åˆ é™¤æ–‡ä»¶å‰6è¡Œæè¿°å¤´ï¼Œæ–¹ä¾¿pandasè¯»å–
!sed -i '1,6d' dataset/annotations/list.txt
```


```python
!head dataset/annotations/list.txt
```

    Abyssinian_100 1 1 1
    Abyssinian_101 1 1 1
    Abyssinian_102 1 1 1
    Abyssinian_103 1 1 1
    Abyssinian_104 1 1 1
    Abyssinian_105 1 1 1
    Abyssinian_106 1 1 1
    Abyssinian_107 1 1 1
    Abyssinian_108 1 1 1
    Abyssinian_109 1 1 1



```python
import pandas as pd
import shutil
import os


# Image CLASS-ID SPECIES BREED ID
# ID: 1:37 Class ids
# SPECIES: 1:Cat 2:Dog
# BREED ID: 1-25:Cat 1:12:Dog
# All images with 1st letter as captial are cat images
# images with small first letter are dog images
# ._Abyssinian_100.png

def copyfile(animal, filename):
    # image\labelåˆ—è¡¨
    file_list = []
    image_file = filename + '.jpg'
    label_file = filename + '.png'

    if os.path.exists(os.path.join('dataset/images', image_file)):
        shutil.copy(os.path.join('dataset/images', image_file), os.path.join(f'{animal}/images', image_file))
        shutil.copy(os.path.join('dataset/annotations/trimaps', label_file),
                    os.path.join(f'{animal}/labels', label_file))
        temp = os.path.join('images/', image_file) + ' ' + os.path.join('labels/',label_file) + '\n'
        file_list.append(temp)
    with open(os.path.join(animal, animal + '.txt'), 'a') as f:
        f.writelines(file_list)


if __name__ == "__main__":

    data = pd.read_csv('dataset/annotations/list.txt', header=None, sep=' ')
    data.head()

    cat = data[data[2] == 1]
    dog = data[data[2] == 2]

    for item in cat[0]:
        copyfile('cat', item)

    for item in dog[0]:
        copyfile('dog', item)

```


```python
# åˆ é™¤æ— ç”¨æ•°æ®
!rm dataset/ -rf
```

##  4.è®­ç»ƒè‡ªå®šä¹‰çš„æ•°æ®é›†

### 4.1æ–‡ä»¶ç»“æ„

```
â”œâ”€â”€ cat.txt
â”œâ”€â”€ images
â”‚   â”œâ”€â”€ Abyssinian_100.jpg
â”‚   â”œâ”€â”€ Abyssinian_101.jpg
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ labels
â”‚   â”œâ”€â”€ Abyssinian_100.png
â”‚   â”œâ”€â”€ Abyssinian_101.png
â”‚   â”œâ”€â”€ ...
```

### 4.2 åˆ—è¡¨å†…å®¹ï¼š

```
images/Abyssinian_1.jpg labels/Abyssinian_1.png
images/Abyssinian_10.jpg labels/Abyssinian_10.png
images/Abyssinian_100.jpg labels/Abyssinian_100.png
...
```


### 4.3.æ•°æ®æŸ¥çœ‹


```python
%cd ~
from PIL import Image

img=Image.open('cat/images/Abyssinian_123.jpg')
print(img)
img
```

    /home/aistudio
    <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x7F203C05FBD0>





![png](output_11_1.png)




```python
img=Image.open('cat/labels/Abyssinian_123.png')
print(img)
img
```

    <PIL.PngImagePlugin.PngImageFile image mode=L size=500x333 at 0x7F203C0574D0>





![png](output_12_1.png)



## 5.æ ‡ç­¾å¤„ç†
>æ ‡ç­¾æ˜¯ä»0å¼€å§‹æ’åºï¼Œæœ¬é¡¹ç›®çš„æ•°æ®æå–è‡ªOxford-IIIT Pet https://www.robots.ox.ac.uk/~vgg/data/pets å® ç‰©æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ˜¯ä»1å¼€å§‹ç¼–ç ï¼Œæ‰€ä»¥éœ€è¦é‡æ–°ç¼–ç ã€‚èƒŒæ™¯è®¾ç½®ä¸º0ï¼Œå›¾åƒè®¾ç½®ä¸º1.


```python
# æ‰§è¡Œä¸€æ¬¡å³å¯
import pandas as pd
import os
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

def re_label(filename):
    img = plt.imread(filename) * 255.0
    img_label = np.zeros((img.shape[0], img.shape[1]), np.uint8)
    for i in range(img.shape[0]):
        for j in range(img.shape[1]):
            value = img[i, j]
            if value == 2:
                img_label[i, j] = 1
    label0 = Image.fromarray(np.uint8(img_label))
    label0.save( filename)

data=pd.read_csv("cat/cat.txt", header=None, sep=' ') 
for item in data[1]:
    re_label(os.path.join('cat', item))
print('å¤„ç†å®Œæ¯•ï¼')    
```

    å¤„ç†å®Œæ¯•ï¼


# äºŒã€æ•°æ®é›†é¢„å¤„ç†



```python
import os
from sklearn.model_selection import train_test_split
import pandas as pd


def break_data(target, rate=0.2):
    origin_dataset = pd.read_csv("cat/cat.txt", header=None, sep=' ')  # åŠ å…¥å‚æ•°
    train_data, test_data = train_test_split(origin_dataset, test_size=rate)
    train_data,eval_data=train_test_split(train_data, test_size=rate)
    train_filename = os.path.join(target, 'train.txt')
    test_filename = os.path.join(target, 'test.txt')
    eval_filename = os.path.join(target, 'eval.txt')

    train_data.to_csv(train_filename, index=False, sep=' ',  header=None)
    test_data.to_csv(test_filename, index=False, sep=' ', header=None)
    eval_data.to_csv(eval_filename, index=False, sep=' ', header=None)

    print('train_data:',len(train_data))
    print('test_data:',len(test_data))
    print('eval_data:',len(eval_data))

if __name__ == '__main__':
    break_data(target='cat', rate=0.2)
```

    train_data: 1516
    test_data: 475
    eval_data: 380



```python
# æŸ¥çœ‹
!head cat/train.txt
```

    images/Bengal_173.jpg labels/Bengal_173.png
    images/Siamese_179.jpg labels/Siamese_179.png
    images/British_Shorthair_201.jpg labels/British_Shorthair_201.png
    images/Russian_Blue_60.jpg labels/Russian_Blue_60.png
    images/British_Shorthair_93.jpg labels/British_Shorthair_93.png
    images/British_Shorthair_26.jpg labels/British_Shorthair_26.png
    images/British_Shorthair_209.jpg labels/British_Shorthair_209.png
    images/British_Shorthair_101.jpg labels/British_Shorthair_101.png
    images/British_Shorthair_269.jpg labels/British_Shorthair_269.png
    images/Ragdoll_59.jpg labels/Ragdoll_59.png


# ä¸‰ã€é…ç½®


```python
# å·²é…ç½®å¥½ï¼Œå¯ä»¥ä¸ç”¨å¤åˆ¶äº†
# !cp PaddleSeg/configs/quick_start/bisenet_optic_disc_512x512_1k.yml ~/bisenet_optic_disc_512x512_1k.yml
```

ä¿®æ”¹ bisenet_optic_disc_512x512_1k.ymlï¼Œè¦æ³¨æ„ä¸€ä¸‹å‡ ç‚¹ï¼š

* 1.æ•°æ®é›†è·¯å¾„é…ç½®
* 2.num_classesè®¾ç½®ï¼ŒèƒŒæ™¯ä¸ç®—
* 3.transformsè®¾ç½®
* 4.lossè®¾ç½®

```
batch_size: 600
iters: 5000

train_dataset:   
  type: Dataset
  dataset_root: /home/aistudio/cat/
  train_path: /home/aistudio/cat/train.txt
  num_classes: 2
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
    - type: RandomPaddingCrop
      crop_size: [224, 224]
    - type: RandomHorizontalFlip
    - type: RandomDistort
      brightness_range: 0.4
      contrast_range: 0.4
      saturation_range: 0.4
    - type: Normalize
  mode: train


val_dataset: 
  type: Dataset
  dataset_root: /home/aistudio/cat/
  val_path: /home/aistudio/cat/eval.txt
  num_classes: 2
  transforms:
    - type: Normalize
  mode: val

optimizer:
  type: sgd
  momentum: 0.9
  weight_decay: 0.0005

lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.05
  end_lr: 0
  power: 0.9

loss:
  types:
    - type: CrossEntropyLoss
  coef: [1]

model:
  type: FCN
  backbone:
    type: HRNet_W18_Small_V1
    align_corners: False
  num_classes: 2
  pretrained: Null


```

# å››ã€è®­ç»ƒ


```python
%cd ~/PaddleSeg/
! python train.py --config  ../bisenet_optic_disc_512x512_1k.yml\
    --do_eval \
    --use_vdl \
    --save_interval 100 \
    --save_dir output
```

```
2021-11-13 19:30:52 [INFO]	[TRAIN] epoch: 1105, iter: 2210/5000, loss: 0.1849, lr: 0.029586, batch_cost: 8.8180, reader_cost: 7.73956, ips: 68.0427 samples/sec | ETA 06:50:02
2021-11-13 19:32:18 [INFO]	[TRAIN] epoch: 1110, iter: 2220/5000, loss: 0.1768, lr: 0.029490, batch_cost: 8.6004, reader_cost: 7.52235, ips: 69.7641 samples/sec | ETA 06:38:29
2021-11-13 19:33:47 [INFO]	[TRAIN] epoch: 1115, iter: 2230/5000, loss: 0.1791, lr: 0.029395, batch_cost: 8.8851, reader_cost: 7.80702, ips: 67.5288 samples/sec | ETA 06:50:11
2021-11-13 19:35:14 [INFO]	[TRAIN] epoch: 1120, iter: 2240/5000, loss: 0.1835, lr: 0.029299, batch_cost: 8.6699, reader_cost: 7.59314, ips: 69.2053 samples/sec | ETA 06:38:48
2021-11-13 19:36:41 [INFO]	[TRAIN] epoch: 1125, iter: 2250/5000, loss: 0.1815, lr: 0.029204, batch_cost: 8.7713, reader_cost: 7.68169, ips: 68.4051 samples/sec | ETA 06:42:00
2021-11-13 19:38:08 [INFO]	[TRAIN] epoch: 1130, iter: 2260/5000, loss: 0.1833, lr: 0.029108, batch_cost: 8.7045, reader_cost: 7.62504, ips: 68.9299 samples/sec | ETA 06:37:30
2021-11-13 19:39:35 [INFO]	[TRAIN] epoch: 1135, iter: 2270/5000, loss: 0.1741, lr: 0.029013, batch_cost: 8.7032, reader_cost: 7.61708, ips: 68.9401 samples/sec | ETA 06:35:59
2021-11-13 19:41:03 [INFO]	[TRAIN] epoch: 1140, iter: 2280/5000, loss: 0.1810, lr: 0.028917, batch_cost: 8.8020, reader_cost: 7.72264, ips: 68.1664 samples/sec | ETA 06:39:01
2021-11-13 19:42:33 [INFO]	[TRAIN] epoch: 1145, iter: 2290/5000, loss: 0.1799, lr: 0.028821, batch_cost: 8.9336, reader_cost: 7.84692, ips: 67.1623 samples/sec | ETA 06:43:30
2021-11-13 19:44:02 [INFO]	[TRAIN] epoch: 1150, iter: 2300/5000, loss: 0.1756, lr: 0.028726, batch_cost: 8.9216, reader_cost: 7.84517, ips: 67.2524 samples/sec | ETA 06:41:28
2021-11-13 19:44:02 [INFO]	Start evaluating (total_samples: 380, total_iters: 380)...
380/380 [==============================] - 15s 40ms/step - batch_cost: 0.0394 - reader cost: 0.001
2021-11-13 19:44:17 [INFO]	[EVAL] #Images: 380 mIoU: 0.7640 Acc: 0.8681 Kappa: 0.7330 
2021-11-13 19:44:17 [INFO]	[EVAL] Class IoU: 
[0.7378 0.7902]
2021-11-13 19:44:17 [INFO]	[EVAL] Class Acc: 
[0.7925 0.9347]
2021-11-13 19:44:17 [INFO]	[EVAL] The model with the best validation mIoU (0.7874) was saved at iter 2100.
```

# äº”ã€æµ‹è¯•


```python
!python val.py \
       --config  /home/aistudio/bisenet_optic_disc_512x512_1k.yml\
       --model_path output/best_model/model.pdparams
```

    2021-11-13 19:48:13 [INFO]	
    ---------------Config Information---------------
    batch_size: 600
    iters: 5000
    loss:
      coef:
      - 1
      types:
      - type: CrossEntropyLoss
    lr_scheduler:
      end_lr: 0
      learning_rate: 0.05
      power: 0.9
      type: PolynomialDecay
    model:
      backbone:
        align_corners: false
        type: HRNet_W18_Small_V1
      num_classes: 2
      pretrained: null
      type: FCN
    optimizer:
      momentum: 0.9
      type: sgd
      weight_decay: 0.0005
    train_dataset:
      dataset_root: /home/aistudio/cat/
      mode: train
      num_classes: 2
      train_path: /home/aistudio/cat/train.txt
      transforms:
      - max_scale_factor: 2.0
        min_scale_factor: 0.5
        scale_step_size: 0.25
        type: ResizeStepScaling
      - crop_size:
        - 224
        - 224
        type: RandomPaddingCrop
      - type: RandomHorizontalFlip
      - brightness_range: 0.4
        contrast_range: 0.4
        saturation_range: 0.4
        type: RandomDistort
      - type: Normalize
      type: Dataset
    val_dataset:
      dataset_root: /home/aistudio/cat/
      mode: val
      num_classes: 2
      transforms:
      - type: Normalize
      type: Dataset
      val_path: /home/aistudio/cat/eval.txt
    ------------------------------------------------
    W1113 19:48:13.707370  4265 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1
    W1113 19:48:13.707428  4265 device_context.cc:422] device: 0, cuDNN Version: 7.6.
    2021-11-13 19:48:19 [INFO]	Loading pretrained model from output/best_model/model.pdparams
    2021-11-13 19:48:19 [INFO]	There are 363/363 variables loaded into FCN.
    2021-11-13 19:48:19 [INFO]	Loaded trained params of model successfully
    2021-11-13 19:48:19 [INFO]	Start evaluating (total_samples: 380, total_iters: 380)...
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int32, but right dtype is paddle.bool, the right dtype will convert to paddle.int32
      format(lhs_dtype, rhs_dtype, lhs_dtype))
    /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.bool, the right dtype will convert to paddle.int64
      format(lhs_dtype, rhs_dtype, lhs_dtype))
    380/380 [==============================] - 15s 41ms/step - batch_cost: 0.0405 - reader cost: 0.00
    2021-11-13 19:48:35 [INFO]	[EVAL] #Images: 380 mIoU: 0.7874 Acc: 0.8838 Kappa: 0.7616 
    2021-11-13 19:48:35 [INFO]	[EVAL] Class IoU: 
    [0.7566 0.8181]
    2021-11-13 19:48:35 [INFO]	[EVAL] Class Acc: 
    [0.8349 0.9211]


```
380/380 [==============================] - 15s 41ms/step - batch_cost: 0.0405 - reader cost: 0.00
2021-11-13 19:48:35 [INFO]	[EVAL] #Images: 380 mIoU: 0.7874 Acc: 0.8838 Kappa: 0.7616 
2021-11-13 19:48:35 [INFO]	[EVAL] Class IoU: 
[0.7566 0.8181]
2021-11-13 19:48:35 [INFO]	[EVAL] Class Acc: 
[0.8349 0.9211]
```

# å…­ã€å¯¼å‡ºé™æ€æ¨¡å‹


```python
!python export.py \
       --config /home/aistudio/bisenet_optic_disc_512x512_1k.yml\
       --model_path output/best_model/model.pdparams
```

```
 op_type, op_type, EXPRESSION_MAP[method_name]))
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:322: UserWarning: /tmp/tmp_l3u6xjv.py:58
The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.
  op_type, op_type, EXPRESSION_MAP[method_name]))
2021-11-03 01:01:11 [INFO]	Model is saved in ./output.
```

# ä¸ƒã€é¢„æµ‹

deploy.yaml

```
Deploy:
  model: model.pdmodel
  params: model.pdiparams
  transforms:
  - type: Normalize
```


```python
# å®‰è£…paddleseg
!pip install -e .
```


```python
# é¢„æµ‹
%cd ~/PaddleSeg/
!python deploy/python/infer.py --config output/deploy.yaml  --image_path /home/aistudio/cat/images/Bombay_130.jpg
```

    /home/aistudio/PaddleSeg



```python
# æ‰“å°åŸå›¾
from PIL import Image
img=Image.open('/home/aistudio/cat/images/Bombay_130.jpg')
img
```




![png](output_33_0.png)




```python
# æ‰“å°è¾“å‡ºå›¾ï¼Œé¢œè‰²å¯è°ƒ
from PIL import Image
img=Image.open('/home/aistudio/PaddleSeg/output/Bombay_130.png')
img
```




![png](output_34_0.png)



# å…«ã€hubéƒ¨ç½²

hubéƒ¨ç½²å¯å‚è€ƒï¼š[PaddleHub Moduleè½¬æ¢](https://aistudio.baidu.com/aistudio/projectdetail/641317)

å·²ç”¨hubéƒ¨ç½²ï¼Œå¯é€šè¿‡å‘½ä»¤è¡Œæˆ–è€…pythonæ¥æŠ å›¾å•¦ï¼ï¼Œå…·ä½“hubæ–‡ä»¶è§ç›®å½•å‹ç¼©åŒ…catseg_mobile.zip

```
hub run catseg_mobile --input_path .\cat1.jpg
```

![](https://ai-studio-static-online.cdn.bcebos.com/102fb28c7d0c4b8cada525f690296434e7d53bc2213c4c1890fcccdc2f9b90b5)


![](https://ai-studio-static-online.cdn.bcebos.com/34fd4a91a88f4a58bf3e962807c2e26e2b5666731c27490a8626942eb014c1ca)



```python

```
